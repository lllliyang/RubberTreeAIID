# RubberTreeAIID ğŸŒ¿

**RubberTreeAIID** is an intelligent rubber plantation management system that integrates UAV-based remote sensing, advanced object detection (YOLOv11 with custom modules), geospatial coordinate extraction, and digital identity tracking via QR codes.

It provides a complete pipeline from image acquisition and processing to automated planting pit detection, geographic localization, and interactive information management through a Vue-based web interface.

---

## ğŸ§  Key Features

- ğŸ” **High-accuracy detection** of rubber tree planting pits from UAV-derived orthophotos (DOM)
- ğŸŒ **Geolocation of planting pits** via affine transformation over DSM data
- ğŸ§© **Improved YOLOv11 model** with custom modules: `C3K2_DDF`, `SCDown`, and `iEMA`
- ğŸ§¾ **QR code generation** for individual planting pit identification and traceability
- ğŸ“Š **Web-based system** for real-time data editing, querying, and visualization
- ğŸ—ƒï¸ **MySQL database integration** for persistent data storage and retrieval

---

## ğŸ“‚ Project Structure

RubberTreeAIID/
â”œâ”€â”€ backend/ # Flask backend server
â”‚ â”œâ”€â”€ app.py # Main API entry
â”‚ â”œâ”€â”€ config.py # Configuration settings
â”‚ â”œâ”€â”€ input/ # Uploaded DOM/DSM files
â”‚ â”œâ”€â”€ output/ # Detection results, coordinates, image tiles
â”‚ â”œâ”€â”€ models/ # Model loading and inference logic
â”‚ â”‚ â””â”€â”€ weights/ # Trained YOLOv11 weights (e.g., best.pt)
â”‚ â”œâ”€â”€ utils/ # Core functional modules:
â”‚ â”‚ â”œâ”€â”€ inference/ # DOM tiling, image inference
â”‚ â”‚ â”œâ”€â”€ transform/ # Affine geolocation
â”‚ â”‚ â”œâ”€â”€ qrcode/ # QR-code generation and encoding
â”‚ â”‚ â”œâ”€â”€ database/ # MySQL interface
â”‚ â”‚ â””â”€â”€ ultralytics/ # Custom YOLOv11 with Addmodule
â”œâ”€â”€ frontend/ # Vue-based frontend
â”‚ â”œâ”€â”€ src/ # Form UI, QR-code view, tree info editing
â”‚ â””â”€â”€ vue.config.js # Frontend config
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md

yaml
Copy
Edit

---

## ğŸ”§ Installation & Setup

### 1. Python Backend (Flask)

```bash
# Create virtual environment
conda create -n rubber_env python=3.9
conda activate rubber_env

# Install dependencies
pip install -r requirements.txt

# Launch backend server
cd backend
python app.py
Server will be running at: http://127.0.0.1:5000

2. Vue Frontend
bash
Copy
Edit
cd frontend
npm install
npm run serve
Frontend will be available at: http://localhost:8080

ğŸ§  Model: YOLOv11 + Addmodule
This project uses a customized YOLOv11 model enhanced for small object detection and blurred-edge robustness, built with:

C3K2_DDF: Multi-scale depthwise dilated feature fusion

SCDown: Efficient downsampling block replacing standard convolution

iEMA: Improved Efficient Multi-scale Attention module

Model weight file:

bash
Copy
Edit
backend/models/weights/best.pt
Modified YOLO source located in:

bash
Copy
Edit
backend/utils/ultralytics/
ğŸ›°ï¸ Spatial Localization
For each DOM tile with detected planting pits:

Extract pixel coordinates of bounding box centers

Match with DSM-derived pixel-to-geocoordinate mapping

Apply affine transformation to convert pixel points to EPSG:4326 (WGS84) geocoordinates

Store lat/lon/elevation in MySQL along with tree metadata

ğŸ“· Sample Workflow
css
Copy
Edit
[ UAV DOM/DSM Images ]
         â†“
[ Image Tiling (640Ã—640) ]
         â†“
[ YOLOv11 Detection ]
         â†“
[ Affine Coordinate Extraction ]
         â†“
[ Result Saving: Detected Image + .txt + Geo CSV ]
         â†“
[ QR Code Generation ]
         â†“
[ Web Interface Visualization & Editing ]
ğŸ“¬ Output Format
Each detection will generate:

det_xxx.png: Annotated detection image

det_xxx.txt: Bounding box info (YOLO format)

det_xxx.csv: Geographic coordinates (lon, lat, elevation)

qrcode_xxx.png: QR code image embedding tree metadata

ğŸ›  TODO (Roadmap)
 Integrate RTK-GNSS high-precision geolocation

 Add tree-level phenotypic traits (e.g., height, crown diameter)

 Web-based batch editing and Excel import/export

 Support for mobile-side QR scan entry

ğŸ“„ License
This project is released under an academic use license.
For commercial licensing or collaboration inquiries, please contact the author.
